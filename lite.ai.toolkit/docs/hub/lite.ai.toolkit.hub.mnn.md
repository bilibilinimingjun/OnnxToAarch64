# Lite.AI.ToolKit.Hub.MNN

You can download all the pretrained models files of MNN format from ([Baidu Drive](https://pan.baidu.com/s/1KyO-bCYUv6qPq2M8BH_Okg) code: 9v63) 

## Object Detection.

<div id="lite.ai.toolkit.hub.mnn-object-detection"></div>

|                        Class                        |        Pretrained MNN Files        |               Rename or Converted From (Repo)                | Size  |
|:---------------------------------------------------:|:----------------------------------:|:------------------------------------------------------------:|:-----:|
|         *lite::mnn::cv::detection::NanoDet*         |         nanodet_m_0.5x.mnn         |        [nanodet](https://github.com/RangiLyu/nanodet)        | 1.1Mb |
|         *lite::mnn::cv::detection::NanoDet*         |           nanodet_m.mnn            |        [nanodet](https://github.com/RangiLyu/nanodet)        | 3.6Mb |
|         *lite::mnn::cv::detection::NanoDet*         |         nanodet_m_1.5x.mnn         |        [nanodet](https://github.com/RangiLyu/nanodet)        | 7.9Mb |
|         *lite::mnn::cv::detection::NanoDet*         |       nanodet_m_1.5x_416.mnn       |        [nanodet](https://github.com/RangiLyu/nanodet)        | 7.9Mb |
|         *lite::mnn::cv::detection::NanoDet*         |         nanodet_m_416.mnn          |        [nanodet](https://github.com/RangiLyu/nanodet)        | 3.6Mb |
|         *lite::mnn::cv::detection::NanoDet*         |           nanodet_g.mnn            |        [nanodet](https://github.com/RangiLyu/nanodet)        | 14Mb  |
|         *lite::mnn::cv::detection::NanoDet*         |           nanodet_t.mnn            |        [nanodet](https://github.com/RangiLyu/nanodet)        | 5.1Mb |
|         *lite::mnn::cv::detection::NanoDet*         |     nanodet-RepVGG-A0_416.mnn      |        [nanodet](https://github.com/RangiLyu/nanodet)        | 26Mb  |
| *lite::mnn::cv::detection::NanoDetEfficientNetLite* | nanodet-EfficientNet-Lite0_320.mnn |        [nanodet](https://github.com/RangiLyu/nanodet)        | 12Mb  |
| *lite::mnn::cv::detection::NanoDetEfficientNetLite* | nanodet-EfficientNet-Lite1_416.mnn |        [nanodet](https://github.com/RangiLyu/nanodet)        | 15Mb  |
| *lite::mnn::cv::detection::NanoDetEfficientNetLite* | nanodet-EfficientNet-Lite2_512.mnn |        [nanodet](https://github.com/RangiLyu/nanodet)        | 18Mb  |
|          *lite::mnn::cv::detection::YoloX*          |            yolox_x.mnn             |    [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)    | 378Mb |
|          *lite::mnn::cv::detection::YoloX*          |            yolox_l.mnn             |    [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)    | 207Mb |
|          *lite::mnn::cv::detection::YoloX*          |            yolox_m.mnn             |    [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)    | 97Mb  |
|          *lite::mnn::cv::detection::YoloX*          |            yolox_s.mnn             |    [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)    | 34Mb  |
|          *lite::mnn::cv::detection::YoloX*          |           yolox_tiny.mnn           |    [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)    | 19Mb  |
|          *lite::mnn::cv::detection::YoloX*          |           yolox_nano.mnn           |    [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)    | 3.5Mb |
|          *lite::mnn::cv::detection::YOLOP*          |         yolop-320-320.mnn          |           [YOLOP](https://github.com/hustvl/YOLOP)           | 30Mb  |
|          *lite::mnn::cv::detection::YOLOP*          |         yolop-640-640.mnn          |           [YOLOP](https://github.com/hustvl/YOLOP)           | 30Mb  |
|          *lite::mnn::cv::detection::YOLOP*          |        yolop-1280-1280.mnn         |           [YOLOP](https://github.com/hustvl/YOLOP)           | 30Mb  |
|         *lite::mnn::cv::detection::YoloV5*          |            yolov5l.mnn             |       [yolov5](https://github.com/ultralytics/yolov5)        | 188Mb |
|         *lite::mnn::cv::detection::YoloV5*          |            yolov5m.mnn             |       [yolov5](https://github.com/ultralytics/yolov5)        | 85Mb  |
|         *lite::mnn::cv::detection::YoloV5*          |            yolov5s.mnn             |       [yolov5](https://github.com/ultralytics/yolov5)        | 29Mb  |
|         *lite::mnn::cv::detection::YoloV5*          |            yolov5x.mnn             |       [yolov5](https://github.com/ultralytics/yolov5)        | 351Mb | 
|      *lite::mnn::cv::detection::YoloX_V_0_1_1*      |         yolox_x_v0.1.1.mnn         |    [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)    | 378Mb |
|      *lite::mnn::cv::detection::YoloX_V_0_1_1*      |         yolox_l_v0.1.1.mnn         |    [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)    | 207Mb |
|      *lite::mnn::cv::detection::YoloX_V_0_1_1*      |         yolox_m_v0.1.1.mnn         |    [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)    | 97Mb  |
|      *lite::mnn::cv::detection::YoloX_V_0_1_1*      |         yolox_s_v0.1.1.mnn         |    [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)    | 34Mb  |
|      *lite::mnn::cv::detection::YoloX_V_0_1_1*      |       yolox_tiny_v0.1.1.mnn        |    [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)    | 19Mb  |
|      *lite::mnn::cv::detection::YoloX_V_0_1_1*      |       yolox_nano_v0.1.1.mnn        |    [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)    | 3.5Mb |
|          *lite::mnn::cv::detection::YoloR*          |        yolor-p6-320-320.mnn        |         [yolor](https://github.com/WongKinYiu/yolor)         | 157Mb |
|          *lite::mnn::cv::detection::YoloR*          |        yolor-p6-640-640.mnn        |         [yolor](https://github.com/WongKinYiu/yolor)         | 157Mb |
|          *lite::mnn::cv::detection::YoloR*          |     yolor-ssss-s2d-640-640.mnn     |         [yolor](https://github.com/WongKinYiu/yolor)         | 50Mb  |
|      *lite::mnn::cv::detection::YoloV5_V_6_0*       |     yolov5l.640-640.v.6.0.mnn      |       [yolov5](https://github.com/ultralytics/yolov5)        | 178Mb |
|      *lite::mnn::cv::detection::YoloV5_V_6_0*       |     yolov5m.640-640.v.6.0.mnn      |       [yolov5](https://github.com/ultralytics/yolov5)        | 81Mb  |
|      *lite::mnn::cv::detection::YoloV5_V_6_0*       |     yolov5s.640-640.v.6.0.mnn      |       [yolov5](https://github.com/ultralytics/yolov5)        | 28Mb  |
|      *lite::mnn::cv::detection::YoloV5_V_6_0*       |     yolov5n.640-640.v.6.0.mnn      |       [yolov5](https://github.com/ultralytics/yolov5)        | 7.5Mb |
|      *lite::mnn::cv::detection::YoloV5_V_6_0*       |     yolov5l6.640-640.v.6.0.mnn     |       [yolov5](https://github.com/ultralytics/yolov5)        | 294Mb |
|      *lite::mnn::cv::detection::YoloV5_V_6_0*       |     yolov5m6.640-640.v.6.0.mnn     |       [yolov5](https://github.com/ultralytics/yolov5)        | 128Mb |
|      *lite::mnn::cv::detection::YoloV5_V_6_0*       |     yolov5s6.640-640.v.6.0.mnn     |       [yolov5](https://github.com/ultralytics/yolov5)        | 50Mb  |
|      *lite::mnn::cv::detection::YoloV5_V_6_0*       |     yolov5n6.640-640.v.6.0.mnn     |       [yolov5](https://github.com/ultralytics/yolov5)        | 14Mb  |
|      *lite::mnn::cv::detection::YoloV5_V_6_0*       |    yolov5l6.1280-1280.v.6.0.mnn    |       [yolov5](https://github.com/ultralytics/yolov5)        | 294Mb |
|      *lite::mnn::cv::detection::YoloV5_V_6_0*       |    yolov5m6.1280-1280.v.6.0.mnn    |       [yolov5](https://github.com/ultralytics/yolov5)        | 128Mb |
|      *lite::mnn::cv::detection::YoloV5_V_6_0*       |    yolov5s6.1280-1280.v.6.0.mnn    |       [yolov5](https://github.com/ultralytics/yolov5)        | 50Mb  |
|      *lite::mnn::cv::detection::YoloV5_V_6_0*       |    yolov5n6.1280-1280.v.6.0.mnn    |       [yolov5](https://github.com/ultralytics/yolov5)        | 14Mb  |
|       *lite::mnn::cv::detection::NanoDetPlus*       |       nanodet-plus-m_320.mnn       |        [nanodet](https://github.com/RangiLyu/nanodet)        | 4.5Mb |
|       *lite::mnn::cv::detection::NanoDetPlus*       |       nanodet-plus-m_416.mnn       |        [nanodet](https://github.com/RangiLyu/nanodet)        | 4.5Mb |
|       *lite::mnn::cv::detection::NanoDetPlus*       |    nanodet-plus-m-1.5x_320.mnn     |        [nanodet](https://github.com/RangiLyu/nanodet)        | 9.4Mb |
|       *lite::mnn::cv::detection::NanoDetPlus*       |    nanodet-plus-m-1.5x_416.mnn     |        [nanodet](https://github.com/RangiLyu/nanodet)        | 9.4Mb |
|        *lite::mnn::cv::detection::InsectDet*        |   quarrying_insect_detector.mnn    | [InsectID](https://github.com/quarrying/quarrying-insect-id) | 22Mb  |
|      *lite::mnn::cv::detection::YoloV5_V_6_1*       |      yolov5l.v6.1.640x640.mnn      |       [yolov5](https://github.com/ultralytics/yolov5)        | 178Mb |
|      *lite::mnn::cv::detection::YoloV5_V_6_1*       |     yolov5l.v6.1.1280x1280.mnn     |       [yolov5](https://github.com/ultralytics/yolov5)        | 178Mb |
|      *lite::mnn::cv::detection::YoloV5_V_6_1*       |      yolov5m.v6.1.640x640.mnn      |       [yolov5](https://github.com/ultralytics/yolov5)        | 81Mb  |
|      *lite::mnn::cv::detection::YoloV5_V_6_1*       |      yolov5x.v6.1.640x640.mnn      |       [yolov5](https://github.com/ultralytics/yolov5)        | 332Mb |
|      *lite::mnn::cv::detection::YoloV5_V_6_1*       |     yolov5x.v6.1.1280x1280.mnn     |       [yolov5](https://github.com/ultralytics/yolov5)        | 332Mb |
|      *lite::mnn::cv::detection::YoloV5_V_6_1*       |      yolov5s.v6.1.640x640.mnn      |       [yolov5](https://github.com/ultralytics/yolov5)        | 28Mb  |
|      *lite::mnn::cv::detection::YoloV5_V_6_1*       |      yolov5s.v6.1.320x320.mnn      |       [yolov5](https://github.com/ultralytics/yolov5)        | 28Mb  |
|      *lite::mnn::cv::detection::YoloV5_V_6_1*       |      yolov5n.v6.1.640x640.mnn      |       [yolov5](https://github.com/ultralytics/yolov5)        |  7Mb  |
|      *lite::mnn::cv::detection::YoloV5_V_6_1*       |      yolov5n.v6.1.320x320.mnn      |       [yolov5](https://github.com/ultralytics/yolov5)        |  7Mb  |
|         *lite::mnn::cv::detection::YOLOv6*          |        yolov6n-320x320.mnn         |         [YOLOv6](https://github.com/meituan/YOLOv6)          | 17Mb  |
|         *lite::mnn::cv::detection::YOLOv6*          |        yolov6n-640x640.mnn         |         [YOLOv6](https://github.com/meituan/YOLOv6)          | 17Mb  |
|         *lite::mnn::cv::detection::YOLOv6*          |        yolov6s-320x320.mnn         |         [YOLOv6](https://github.com/meituan/YOLOv6)          | 66Mb  |
|         *lite::mnn::cv::detection::YOLOv6*          |        yolov6n-640x640.mnn         |         [YOLOv6](https://github.com/meituan/YOLOv6)          | 66Mb  |
|         *lite::mnn::cv::detection::YOLOv6*          |        yolov6t-640x640.mnn         |         [YOLOv6](https://github.com/meituan/YOLOv6)          | 57Mb  |


## Matting.

<div id="lite.ai.toolkit.hub.mnn-matting"></div>

|                     Class                     |                Pretrained MNN Files                |                               Rename or Converted From (Repo)                               | Size  |
|:---------------------------------------------:|:--------------------------------------------------:|:-------------------------------------------------------------------------------------------:|:-----:|
| *lite::mnn::cv::matting::RobustVideoMatting*  |              rvm_mobilenetv3_fp32.mnn              |            [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting)             | 14Mb  |
| *lite::mnn::cv::matting::RobustVideoMatting*  |          rvm_mobilenetv3_fp32-480-480.mnn          |            [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting)             | 14Mb  |
| *lite::mnn::cv::matting::RobustVideoMatting*  |          rvm_mobilenetv3_fp32-480-640.mnn          |            [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting)             | 14Mb  |
| *lite::mnn::cv::matting::RobustVideoMatting*  |          rvm_mobilenetv3_fp32-640-480.mnn          |            [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting)             | 14Mb  |
| *lite::mnn::cv::matting::RobustVideoMatting*  |         rvm_mobilenetv3_fp32-1080-1920.mnn         |            [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting)             | 14Mb  |
| *lite::mnn::cv::matting::RobustVideoMatting*  |               rvm_resnet50_fp32.mnn                |            [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting)             | 50Mb  |
| *lite::mnn::cv::matting::RobustVideoMatting*  |           rvm_resnet50_fp32-480-480.mnn            |            [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting)             | 50Mb  |
| *lite::mnn::cv::matting::RobustVideoMatting*  |           rvm_resnet50_fp32-480-640.mnn            |            [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting)             | 50Mb  |
| *lite::mnn::cv::matting::RobustVideoMatting*  |           rvm_resnet50_fp32-640-480.mnn            |            [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting)             | 50Mb  |
| *lite::mnn::cv::matting::RobustVideoMatting*  |          rvm_resnet50_fp32-1080-1920.mnn           |            [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting)             | 50Mb  |
|      *lite::mnn::cv::matting::MGMatting*      |               MGMatting-DIM-100k.mnn               |                    [MGMatting](https://github.com/yucornetto/MGMatting)                     | 113Mb |
|      *lite::mnn::cv::matting::MGMatting*      |               MGMatting-RWP-100k.mnn               |                    [MGMatting](https://github.com/yucornetto/MGMatting)                     | 113Mb |
|       *lite::mnn::cv::matting::MODNet*        | modnet_photographic_portrait_matting-1024x1024.mnn |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
|       *lite::mnn::cv::matting::MODNet*        | modnet_photographic_portrait_matting-1024x512.mnn  |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
|       *lite::mnn::cv::matting::MODNet*        |  modnet_photographic_portrait_matting-256x256.mnn  |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
|       *lite::mnn::cv::matting::MODNet*        |  modnet_photographic_portrait_matting-256x512.mnn  |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
|       *lite::mnn::cv::matting::MODNet*        | modnet_photographic_portrait_matting-512x1024.mnn  |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
|       *lite::mnn::cv::matting::MODNet*        |  modnet_photographic_portrait_matting-512x256.mnn  |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
|       *lite::mnn::cv::matting::MODNet*        |  modnet_photographic_portrait_matting-512x512.mnn  |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
|       *lite::mnn::cv::matting::MODNet*        |    modnet_webcam_portrait_matting-1024x1024.mnn    |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
|       *lite::mnn::cv::matting::MODNet*        |    modnet_webcam_portrait_matting-1024x512.mnn     |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
|       *lite::mnn::cv::matting::MODNet*        |     modnet_webcam_portrait_matting-256x256.mnn     |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
|       *lite::mnn::cv::matting::MODNet*        |     modnet_webcam_portrait_matting-256x512.mnn     |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
|       *lite::mnn::cv::matting::MODNet*        |    modnet_webcam_portrait_matting-512x1024.mnn     |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
|       *lite::mnn::cv::matting::MODNet*        |     modnet_webcam_portrait_matting-512x256.mnn     |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
|       *lite::mnn::cv::matting::MODNet*        |     modnet_webcam_portrait_matting-512x512.mnn     |                         [MODNet](https://github.com/ZHKKKe/MODNet)                          | 24Mb  |
| *lite::mnn::cv::matting::BackgroundMattingV2* |         BGMv2_mobilenetv2-256x256-full.mnn         |           [BackgroundMattingV2](https://github.com/PeterL1n/BackgroundMattingV2)            | 20Mb  |
| *lite::mnn::cv::matting::BackgroundMattingV2* |         BGMv2_mobilenetv2-512x512-full.mnn         |           [BackgroundMattingV2](https://github.com/PeterL1n/BackgroundMattingV2)            | 20Mb  |
| *lite::mnn::cv::matting::BackgroundMattingV2* |        BGMv2_mobilenetv2-1080x1920-full.mnn        |           [BackgroundMattingV2](https://github.com/PeterL1n/BackgroundMattingV2)            | 20Mb  |
| *lite::mnn::cv::matting::BackgroundMattingV2* |        BGMv2_mobilenetv2-2160x3840-full.mnn        |           [BackgroundMattingV2](https://github.com/PeterL1n/BackgroundMattingV2)            | 20Mb  |
| *lite::mnn::cv::matting::BackgroundMattingV2* |         BGMv2_resnet50-1080x1920-full.mnn          |           [BackgroundMattingV2](https://github.com/PeterL1n/BackgroundMattingV2)            | 20Mb  |
| *lite::mnn::cv::matting::BackgroundMattingV2* |         BGMv2_resnet50-2160x3840-full.mnn          |           [BackgroundMattingV2](https://github.com/PeterL1n/BackgroundMattingV2)            | 20Mb  |
| *lite::mnn::cv::matting::BackgroundMattingV2* |         BGMv2_resnet101-2160x3840-full.mnn         |           [BackgroundMattingV2](https://github.com/PeterL1n/BackgroundMattingV2)            | 154Mb |
| *lite::mnn::cv::matting::MobileHumanMatting*  |          mobile_human_matting_256x256.mnn          | [mobile_phone_human_matting_](https://github.com/lizhengwei1992/mobile_phone_human_matting) |  3Mb  |
| *lite::mnn::cv::matting::MobileHumanMatting*  |          mobile_human_matting_128x128.mnn          | [mobile_phone_human_matting_](https://github.com/lizhengwei1992/mobile_phone_human_matting) |  3Mb  |
| *lite::mnn::cv::matting::MobileHumanMatting*  |          mobile_human_matting_320x320.mnn          | [mobile_phone_human_matting_](https://github.com/lizhengwei1992/mobile_phone_human_matting) |  3Mb  |
| *lite::mnn::cv::matting::MobileHumanMatting*  |          mobile_human_matting_512x512.mnn          | [mobile_phone_human_matting_](https://github.com/lizhengwei1992/mobile_phone_human_matting) |  3Mb  |

## Face Recognition.

<div id="lite.ai.toolkit.hub.mnn-face-recognition"></div>  


|                     Class                      |                  Pretrained MNN Files                  |                    Rename or Converted From (Repo)                     | Size  |
|:----------------------------------------------:|:------------------------------------------------------:|:----------------------------------------------------------------------:|:-----:|
|     *lite::mnn::cv::faceid::GlintArcFace*      |                ms1mv3_arcface_r100.mnn                 |       [insightface](https://github.com/deepinsight/insightface)        | 248Mb |
|     *lite::mnn::cv::faceid::GlintArcFace*      |                 ms1mv3_arcface_r50.mnn                 |       [insightface](https://github.com/deepinsight/insightface)        | 166Mb |
|     *lite::mnn::cv::faceid::GlintArcFace*      |                 ms1mv3_arcface_r34.mnn                 |       [insightface](https://github.com/deepinsight/insightface)        | 130Mb |
|     *lite::mnn::cv::faceid::GlintArcFace*      |                 ms1mv3_arcface_r18.mnn                 |       [insightface](https://github.com/deepinsight/insightface)        | 91Mb  |
|     *lite::mnn::cv::faceid::GlintCosFace*      |               glint360k_cosface_r100.mnn               |       [insightface](https://github.com/deepinsight/insightface)        | 248Mb |
|     *lite::mnn::cv::faceid::GlintCosFace*      |               glint360k_cosface_r50.mnn                |       [insightface](https://github.com/deepinsight/insightface)        | 166Mb |
|     *lite::mnn::cv::faceid::GlintCosFace*      |               glint360k_cosface_r34.mnn                |       [insightface](https://github.com/deepinsight/insightface)        | 130Mb |
|     *lite::mnn::cv::faceid::GlintCosFace*      |               glint360k_cosface_r18.mnn                |       [insightface](https://github.com/deepinsight/insightface)        | 91Mb  |
|    *lite::mnn::cv::faceid::GlintPartialFC*     |             partial_fc_glint360k_r100.mnn              |       [insightface](https://github.com/deepinsight/insightface)        | 248Mb |
|    *lite::mnn::cv::faceid::GlintPartialFC*     |              partial_fc_glint360k_r50.mnn              |       [insightface](https://github.com/deepinsight/insightface)        | 91Mb  |
|        *lite::mnn::cv::faceid::FaceNet*        |              facenet_vggface2_resnet.mnn               |       [facenet...](https://github.com/timesler/facenet-pytorch)        | 89Mb  |
|        *lite::mnn::cv::faceid::FaceNet*        |            facenet_casia-webface_resnet.mnn            |       [facenet...](https://github.com/timesler/facenet-pytorch)        | 89Mb  |
|     *lite::mnn::cv::faceid::FocalArcFace*      |              focal-arcface-ms1m-ir152.mnn              |   [face.evoLVe...](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch)   | 269Mb |
|     *lite::mnn::cv::faceid::FocalArcFace*      |          focal-arcface-ms1m-ir50-epoch120.mnn          |   [face.evoLVe...](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch)   | 166Mb |
|     *lite::mnn::cv::faceid::FocalArcFace*      |          focal-arcface-ms1m-ir50-epoch63.mnn           |   [face.evoLVe...](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch)   | 166Mb |
|   *lite::mnn::cv::faceid::FocalAsiaArcFace*    |             focal-arcface-bh-ir50-asia.mnn             |   [face.evoLVe...](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch)   | 166Mb |
| *lite::mnn::cv::faceid::TencentCurricularFace* |          Tencent_CurricularFace_Backbone.mnn           |               [TFace](https://github.com/Tencent/TFace)                | 249Mb |
|    *lite::mnn::cv::faceid::TencentCifpFace*    |        Tencent_Cifp_BUPT_Balancedface_IR_34.mnn        |               [TFace](https://github.com/Tencent/TFace)                | 130Mb |
|    *lite::mnn::cv::faceid::CenterLossFace*     |              CenterLossFace_epoch_100.mnn              |   [center-loss...](https://github.com/louis-she/center-loss.pytorch)   | 280Mb |
|      *lite::mnn::cv::faceid::SphereFace*       |                 sphere20a_20171020.mnn                 |      [sphere...](https://github.com/clcarwin/sphereface_pytorch)       | 86Mb  |
|     *lite::mnn::cv::faceid:MobileFaceNet*      |             MobileFaceNet_Pytorch_068.mnn              |   [MobileFace...](https://github.com/Xiaoccer/MobileFaceNet_Pytorch)   | 3.8Mb |
|    *lite::mnn::cv::faceid:CavaGhostArcFace*    |      cavaface_GhostNet_x1.3_Arcface_Epoch_24.mnn       |     [cavaface...](https://github.com/cavalleria/cavaface.pytorch)      | 15Mb  |
|    *lite::mnn::cv::faceid:CavaCombinedFace*    |        cavaface_IR_SE_100_Combined_Epoch_24.mnn        |     [cavaface...](https://github.com/cavalleria/cavaface.pytorch)      | 250Mb |
|   *lite::mnn::cv::faceid:MobileSEFocalFace*    | face_recognition.pytorch_Mobilenet_se_focal_121000.mnn | [face_recog...](https://github.com/grib0ed0v/face_recognition.pytorch) | 4.5Mb |

## Face Detection.

<div id="lite.ai.toolkit.hub.mnn-face-detection"></div>  

|                     Class                      |            Pretrained MNN Files            |                             Rename or Converted From (Repo)                             |  Size  |
|:----------------------------------------------:|:------------------------------------------:|:---------------------------------------------------------------------------------------:|:------:|
|    *lite::mnn::cv::face::detect::UltraFace*    |           ultraface-rfb-320.mnn            | [Ultra-Light...](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB) | 1.5Mb  |
|    *lite::mnn::cv::face::detect::UltraFace*    |           ultraface-rfb-640.mnn            | [Ultra-Light...](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB) | 1.5Mb  |
|    *lite::mnn::cv::face::detect::UltraFace*    |           ultraface-slim-320.mnn           | [Ultra-Light...](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB) | 1.2Mb  |
|    *lite::mnn::cv::face::detect::UltraFace*    |           ultraface-slim-640.mnn           | [Ultra-Light...](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB) | 1.2Mb  |
|   *lite::mnn::cv::face::detect::RetinaFace*    |     Pytorch_RetinaFace_mobile0.25.mnn      |             [...Retinaface](https://github.com/biubug6/Pytorch_Retinaface)              | 1.6Mb  |
|   *lite::mnn::cv::face::detect::RetinaFace*    | Pytorch_RetinaFace_mobile0.25-640-640.mnn  |             [...Retinaface](https://github.com/biubug6/Pytorch_Retinaface)              | 1.6Mb  |
|   *lite::mnn::cv::face::detect::RetinaFace*    | Pytorch_RetinaFace_mobile0.25-320-320.mnn  |             [...Retinaface](https://github.com/biubug6/Pytorch_Retinaface)              | 1.6Mb  |
|   *lite::mnn::cv::face::detect::RetinaFace*    | Pytorch_RetinaFace_mobile0.25-720-1080.mnn |             [...Retinaface](https://github.com/biubug6/Pytorch_Retinaface)              | 1.6Mb  |
|    *lite::mnn::cv::face::detect::FaceBoxes*    |               FaceBoxes.mnn                |                [FaceBoxes](https://github.com/zisianw/FaceBoxes.PyTorch)                | 3.8Mb  |
|    *lite::mnn::cv::face::detect::FaceBoxes*    |           FaceBoxes-640-640.mnn            |                [FaceBoxes](https://github.com/zisianw/FaceBoxes.PyTorch)                | 3.8Mb  |
|    *lite::mnn::cv::face::detect::FaceBoxes*    |           FaceBoxes-320-320.mnn            |                [FaceBoxes](https://github.com/zisianw/FaceBoxes.PyTorch)                | 3.8Mb  |
|    *lite::mnn::cv::face::detect::FaceBoxes*    |           FaceBoxes-720-1080.mnn           |                [FaceBoxes](https://github.com/zisianw/FaceBoxes.PyTorch)                | 3.8Mb  |
|      *lite::mnn::cv::face::detect::SCRFD*      |        scrfd_500m_shape160x160.mnn         |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 2.5Mb  |
|      *lite::mnn::cv::face::detect::SCRFD*      |        scrfd_500m_shape320x320.mnn         |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 2.5Mb  |
|      *lite::mnn::cv::face::detect::SCRFD*      |        scrfd_500m_shape640x640.mnn         |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 2.5Mb  |
|      *lite::mnn::cv::face::detect::SCRFD*      |     scrfd_500m_bnkps_shape160x160.mnn      |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 2.5Mb  |  
|      *lite::mnn::cv::face::detect::SCRFD*      |     scrfd_500m_bnkps_shape320x320.mnn      |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 2.5Mb  |  
|      *lite::mnn::cv::face::detect::SCRFD*      |     scrfd_500m_bnkps_shape640x640.mnn      |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 2.5Mb  |  
|      *lite::mnn::cv::face::detect::SCRFD*      |         scrfd_1g_shape160x160.mnn          |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 2.7Mb  |
|      *lite::mnn::cv::face::detect::SCRFD*      |         scrfd_1g_shape320x320.mnn          |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 2.7Mb  |
|      *lite::mnn::cv::face::detect::SCRFD*      |         scrfd_1g_shape640x640.mnn          |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 2.7Mb  |
|      *lite::mnn::cv::face::detect::SCRFD*      |        scrfd_2.5g_shape160x160.mnn         |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 3.3Mb  |
|      *lite::mnn::cv::face::detect::SCRFD*      |        scrfd_2.5g_shape320x320.mnn         |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 3.3Mb  |
|      *lite::mnn::cv::face::detect::SCRFD*      |        scrfd_2.5g_shape640x640.mnn         |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 3.3Mb  |
|      *lite::mnn::cv::face::detect::SCRFD*      |     scrfd_2.5g_bnkps_shape160x160.mnn      |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 3.3Mb  |  
|      *lite::mnn::cv::face::detect::SCRFD*      |     scrfd_2.5g_bnkps_shape320x320.mnn      |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 3.3Mb  |  
|      *lite::mnn::cv::face::detect::SCRFD*      |     scrfd_2.5g_bnkps_shape640x640.mnn      |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 3.3Mb  |  
|      *lite::mnn::cv::face::detect::SCRFD*      |         scrfd_10g_shape640x640.mnn         |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 16.9Mb |
|      *lite::mnn::cv::face::detect::SCRFD*      |        scrfd_10g_shape1280x1280.mnn        |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 16.9Mb |
|      *lite::mnn::cv::face::detect::SCRFD*      |      scrfd_10g_bnkps_shape640x640.mnn      |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 16.9Mb |  
|      *lite::mnn::cv::face::detect::SCRFD*      |     scrfd_10g_bnkps_shape1280x1280.mnn     |     [SCRFD](https://github.com/deepinsight/insightface/blob/master/detection/scrfd)     | 16.9Mb |  
|    *lite::mnn::cv::face::detect::YOLO5Face*    |      yolov5face-blazeface-640x640.mnn      |                 [YOLO5Face](https://github.com/deepcam-cn/yolov5-face)                  | 3.4Mb  |
|    *lite::mnn::cv::face::detect::YOLO5Face*    |          yolov5face-l-640x640.mnn          |                 [YOLO5Face](https://github.com/deepcam-cn/yolov5-face)                  | 181Mb  |
|    *lite::mnn::cv::face::detect::YOLO5Face*    |          yolov5face-m-640x640.mnn          |                 [YOLO5Face](https://github.com/deepcam-cn/yolov5-face)                  |  83Mb  |
|    *lite::mnn::cv::face::detect::YOLO5Face*    |        yolov5face-n-0.5-320x320.mnn        |                 [YOLO5Face](https://github.com/deepcam-cn/yolov5-face)                  | 2.5Mb  |
|    *lite::mnn::cv::face::detect::YOLO5Face*    |        yolov5face-n-0.5-640x640.mnn        |                 [YOLO5Face](https://github.com/deepcam-cn/yolov5-face)                  | 4.6Mb  |
|    *lite::mnn::cv::face::detect::YOLO5Face*    |          yolov5face-n-640x640.mnn          |                 [YOLO5Face](https://github.com/deepcam-cn/yolov5-face)                  | 9.5Mb  |
|    *lite::mnn::cv::face::detect::YOLO5Face*    |          yolov5face-s-640x640.mnn          |                 [YOLO5Face](https://github.com/deepcam-cn/yolov5-face)                  |  30Mb  |
|   *lite::mnn::cv::face::detect::FaceBoxesV2*   |          faceboxesv2-640x640.mnn           |                [FaceBoxesV2](https://github.com/jhb86253817/FaceBoxesV2)                | 4.0Mb  |
| *lite::mnn::cv::face::detect::YOLOv5BlazeFace* |      yolov5face-blazeface-640x640.mnn      |                 [YOLO5Face](https://github.com/deepcam-cn/yolov5-face)                  | 3.4Mb  |


## Face Alignment.

<div id="lite.ai.toolkit.hub.mnn-face-alignment"></div>  


|                      Class                      |                     Pretrained MNN Files                     |                  Rename or Converted From (Repo)                   |  Size   |
|:-----------------------------------------------:|:------------------------------------------------------------:|:------------------------------------------------------------------:|:-------:|
|       *lite::mnn::cv::face::align::PFLD*        |                      pfld-106-lite.mnn                       | [pfld_106_...](https://github.com/Hsintao/pfld_106_face_landmarks) |  1.0Mb  |
|       *lite::mnn::cv::face::align::PFLD*        |                       pfld-106-v3.mnn                        | [pfld_106_...](https://github.com/Hsintao/pfld_106_face_landmarks) |  5.5Mb  |
|       *lite::mnn::cv::face::align::PFLD*        |                       pfld-106-v2.mnn                        | [pfld_106_...](https://github.com/Hsintao/pfld_106_face_landmarks) |  5.0Mb  |
|      *lite::mnn::cv::face::align::PFLD98*       |                    PFLD-pytorch-pfld.mnn                     |       [PFLD...](https://github.com/polarisZhao/PFLD-pytorch)       |  4.8Mb  |
|   *lite::mnn::cv::face::align::MobileNetV268*   |       pytorch_face_landmarks_landmark_detection_56.mnn       |  [...landmark](https://github.com/cunjian/pytorch_face_landmark)   |  9.4Mb  |
|  *lite::mnn::cv::face::align::MobileNetV2SE68*  | pytorch_face_landmarks_landmark_detection_56_se_external.mnn |  [...landmark](https://github.com/cunjian/pytorch_face_landmark)   |  11Mb   |
|      *lite::mnn::cv::face::align::PFLD68*       |               pytorch_face_landmarks_pfld.mnn                |  [...landmark](https://github.com/cunjian/pytorch_face_landmark)   |  2.8Mb  |
| *lite::mnn::cv::face::align::FaceLandmarks1000* |                     FaceLandmark1000.mnn                     |   [FaceLandm...](https://github.com/Single430/FaceLandmark1000)    |  2.0Mb  |
|     *lite::mnn::cv::face::align::PIPNet98*      |            pipnet_resnet18_10x98x32x256_wflw.mnn             |          [PIPNet](https://github.com/jhb86253817/PIPNet)           | 44.0Mb  |
|     *lite::mnn::cv::face::align::PIPNet68*      |            pipnet_resnet18_10x68x32x256_300w.mnn             |          [PIPNet](https://github.com/jhb86253817/PIPNet)           | 44.0Mb  |
|     *lite::mnn::cv::face::align::PIPNet29*      |            pipnet_resnet18_10x29x32x256_cofw.mnn             |          [PIPNet](https://github.com/jhb86253817/PIPNet)           | 44.0Mb  |
|     *lite::mnn::cv::face::align::PIPNet19*      |            pipnet_resnet18_10x19x32x256_aflw.mnn             |          [PIPNet](https://github.com/jhb86253817/PIPNet)           | 44.0Mb  |
|     *lite::mnn::cv::face::align::PIPNet98*      |            pipnet_resnet101_10x98x32x256_wflw.mnn            |          [PIPNet](https://github.com/jhb86253817/PIPNet)           | 150.0Mb |
|     *lite::mnn::cv::face::align::PIPNet68*      |            pipnet_resnet101_10x68x32x256_300w.mnn            |          [PIPNet](https://github.com/jhb86253817/PIPNet)           | 150.0Mb |
|     *lite::mnn::cv::face::align::PIPNet29*      |            pipnet_resnet101_10x29x32x256_cofw.mnn            |          [PIPNet](https://github.com/jhb86253817/PIPNet)           | 150.0Mb |
|     *lite::mnn::cv::face::align::PIPNet19*      |            pipnet_resnet101_10x19x32x256_aflw.mnn            |          [PIPNet](https://github.com/jhb86253817/PIPNet)           | 150.0Mb |


## Head Pose Estimation.

<div id="lite.ai.toolkit.hub.mnn-head-pose-estimation"></div>  


|                Class                | Pretrained MNN Files |                  Rename or Converted From (Repo)                   | Size  |
|:-----------------------------------:|:--------------------:|:------------------------------------------------------------------:|:-----:|
| *lite::mnn::cv::face::pose::FSANet* |    fsanet-var.mnn    | [...fsanet...](https://github.com/omasaht/headpose-fsanet-pytorch) | 1.2Mb |
| *lite::mnn::cv::face::pose::FSANet* |    fsanet-1x1.mnn    | [...fsanet...](https://github.com/omasaht/headpose-fsanet-pytorch) | 1.2Mb |

## Face Attributes.

<div id="lite.ai.toolkit.hub.mnn-face-attributes"></div>  


|                     Class                      |                    Pretrained MNN Files                     |                      Rename or Converted From (Repo)                      | Size  |
|:----------------------------------------------:|:-----------------------------------------------------------:|:-------------------------------------------------------------------------:|:-----:|
|   *lite::mnn::cv::face::attr::AgeGoogleNet*    |                      age_googlenet.mnn                      |               [onnx-models](https://github.com/onnx/models)               | 23Mb  |
|  *lite::mnn::cv::face::attr::GenderGoogleNet*  |                    gender_googlenet.mnn                     |               [onnx-models](https://github.com/onnx/models)               | 23Mb  |
|  *lite::mnn::cv::face::attr::EmotionFerPlus*   |                    emotion-ferplus-7.mnn                    |               [onnx-models](https://github.com/onnx/models)               | 33Mb  |
|  *lite::mnn::cv::face::attr::EmotionFerPlus*   |                    emotion-ferplus-8.mnn                    |               [onnx-models](https://github.com/onnx/models)               | 33Mb  |
|      *lite::mnn::cv::face::attr::SSRNet*       |                         ssrnet.mnn                          |         [SSR_Net...](https://github.com/oukohou/SSR_Net_Pytorch)          | 190Kb |
| *lite::mnn::cv::face::attr::EfficientEmotion7* |           face-emotion-recognition-enet_b0_7.mnn            | [face-emo...](https://github.com/HSE-asavchenko/face-emotion-recognition) | 15Mb  |
| *lite::mnn::cv::face::attr::EfficientEmotion8* |      face-emotion-recognition-enet_b0_8_best_afew.mnn       | [face-emo...](https://github.com/HSE-asavchenko/face-emotion-recognition) | 15Mb  |
| *lite::mnn::cv::face::attr::EfficientEmotion8* |      face-emotion-recognition-enet_b0_8_best_vgaf.mnn       | [face-emo...](https://github.com/HSE-asavchenko/face-emotion-recognition) | 15Mb  |
|  *lite::mnn::cv::face::attr::MobileEmotion7*   |          face-emotion-recognition-mobilenet_7.mnn           | [face-emo...](https://github.com/HSE-asavchenko/face-emotion-recognition) | 13Mb  |
|  *lite::mnn::cv::face::attr::ReXNetEmotion7*   | face-emotion-recognition-affectnet_7_vggface2_rexnet150.mnn | [face-emo...](https://github.com/HSE-asavchenko/face-emotion-recognition) | 30Mb  |

## Classification.

<div id="lite.ai.toolkit.hub.mnn-classification"></div>


|                       Class                       |      Pretrained MNN Files       |               Rename or Converted From (Repo)                | Size  |
|:-------------------------------------------------:|:-------------------------------:|:------------------------------------------------------------:|:-----:|
| *lite::mnn::cv::classification:EfficientNetLite4* |    efficientnet-lite4-11.mnn    |        [onnx-models](https://github.com/onnx/models)         | 49Mb  |
|   *lite::mnn::cv::classification::ShuffleNetV2*   |      shufflenet-v2-10.mnn       |        [onnx-models](https://github.com/onnx/models)         | 8.7Mb |
|   *lite::mnn::cv::classification::DenseNet121*    |         densenet121.mnn         |       [torchvision](https://github.com/pytorch/vision)       | 30Mb  |
|     *lite::mnn::cv::classification::GhostNet*     |          ghostnet.mnn           |       [torchvision](https://github.com/pytorch/vision)       | 20Mb  |
|     *lite::mnn::cv::classification::HdrDNet*      |           hardnet.mnn           |       [torchvision](https://github.com/pytorch/vision)       | 13Mb  |
|      *lite::mnn::cv::classification::IBNNet*      |          ibnnet18.mnn           |       [torchvision](https://github.com/pytorch/vision)       | 97Mb  |
|   *lite::mnn::cv::classification::MobileNetV2*    |         mobilenetv2.mnn         |       [torchvision](https://github.com/pytorch/vision)       | 13Mb  |
|      *lite::mnn::cv::classification::ResNet*      |          resnet18.mnn           |       [torchvision](https://github.com/pytorch/vision)       | 44Mb  |
|     *lite::mnn::cv::classification::ResNeXt*      |           resnext.mnn           |       [torchvision](https://github.com/pytorch/vision)       | 95Mb  |
|     *lite::mnn::cv::classification::InsectID*     | quarrying_insect_identifier.mnn | [InsectID](https://github.com/quarrying/quarrying-insect-id) | 27Mb  |
|      *lite::mnn::cv::classification:PlantID*      |   quarrying_planted_model.mnn   |  [PlantID](https://github.com/quarrying/quarrying-plant-id)  | 30Mb  |


## Segmentation.

<div id="lite.ai.toolkit.hub.mnn-segmentation"></div>  


|                         Class                          |            Pretrained MNN Files            |                          Rename or Converted From (Repo)                          | Size  |
|:------------------------------------------------------:|:------------------------------------------:|:---------------------------------------------------------------------------------:|:-----:|
|   *lite::mnn::cv::segmentation::DeepLabV3ResNet101*    |        deeplabv3_resnet101_coco.mnn        |                 [torchvision](https://github.com/pytorch/vision)                  | 232Mb |
|      *lite::mnn::cv::segmentation::FCNResNet101*       |             fcn_resnet101.mnn              |                 [torchvision](https://github.com/pytorch/vision)                  | 207Mb |
|         *lite::mnn::cv::segmentation::HeadSeg*         |          minivision_head_seg.mnn           |          [photo2cartoon](https://github.com/minivision-ai/photo2cartoon)          | 31Mb  |
|     *lite::mnn::cv::segmentation::FastPortraitSeg*     |   fast_portrait_seg_SINet_bi_192_128.mnn   |    [Fast-Portrait...](https://github.com/YexingWan/Fast-Portrait-Segmentation)    | 400k  |
|     *lite::mnn::cv::segmentation::FastPortraitSeg*     |   fast_portrait_seg_SINet_bi_256_160.mnn   |    [Fast-Portrait...](https://github.com/YexingWan/Fast-Portrait-Segmentation)    | 400k  |
|     *lite::mnn::cv::segmentation::FastPortraitSeg*     |   fast_portrait_seg_SINet_bi_320_256.mnn   |    [Fast-Portrait...](https://github.com/YexingWan/Fast-Portrait-Segmentation)    | 400k  |
|    *lite::mnn::cv::segmentation::PortraitSegSINet*     |     ext_portrait_seg_SINet_224x224.mnn     |      [ext_portrait...](https://github.com/clovaai/ext_portrait_segmentation)      | 380k  |
| *lite::mnn::cv::segmentation::PortraitSegExtremeC3Net* |   ext_portrait_seg_ExtremeC3_224x224.mnn   |      [ext_portrait...](https://github.com/clovaai/ext_portrait_segmentation)      | 180k  |
|       *lite::mnn::cv::segmentation::FaceHairSeg*       |         face_hair_seg_224x224.mnn          |                  [face-seg](https://github.com/kampta/face-seg)                   |  18M  |
|         *lite::mnn::cv::segmentation::HairSeg*         |            hairseg_224x224.mnn             | [mobile-semantic-seg](https://github.com/akirasosa/mobile-semantic-segmentation)  |  18M  |
|      *lite::mnn::cv::segmentation::MobileHairSeg*      | mobile_hair_seg_hairmattenetv1_224x224.mnn | [mobile-hair...](https://github.com/wonbeomjang/mobile-hair-segmentation-pytorch) |  14M  |
|      *lite::mnn::cv::segmentation::MobileHairSeg*      | mobile_hair_seg_hairmattenetv2_224x224.mnn | [mobile-hair...](https://github.com/wonbeomjang/mobile-hair-segmentation-pytorch) |  14M  |
|   *lite::mnn::cv::segmentation::FaceParsingBiSeNet*    |          face_parsing_512x512.mnn          |    [face-parsing.PyTorch](https://github.com/zllrunning/face-parsing.PyTorch)     |  50M  |
|   *lite::mnn::cv::segmentation::FaceParsingBiSeNet*    |         face_parsing_1024x1024.mnn         |    [face-parsing.PyTorch](https://github.com/zllrunning/face-parsing.PyTorch)     |  50M  |


## Style Transfer.

<div id="lite.ai.toolkit.hub.mnn-style-transfer"></div>  

|                    Class                    |        Pretrained MNN Files         |                 Rename or Converted From (Repo)                 | Size  |
|:-------------------------------------------:|:-----------------------------------:|:---------------------------------------------------------------:|:-----:|
|  *lite::mnn::cv::style::FastStyleTransfer*  |         style-mosaic-8.mnn          |          [onnx-models](https://github.com/onnx/models)          | 6.4Mb |
|  *lite::mnn::cv::style::FastStyleTransfer*  |          style-candy-9.mnn          |          [onnx-models](https://github.com/onnx/models)          | 6.4Mb |
|  *lite::mnn::cv::style::FastStyleTransfer*  |          style-udnie-8.mnn          |          [onnx-models](https://github.com/onnx/models)          | 6.4Mb |
|  *lite::mnn::cv::style::FastStyleTransfer*  |          style-udnie-9.mnn          |          [onnx-models](https://github.com/onnx/models)          | 6.4Mb |
|  *lite::mnn::cv::style::FastStyleTransfer*  |       style-pointilism-8.mnn        |          [onnx-models](https://github.com/onnx/models)          | 6.4Mb |
|  *lite::mnn::cv::style::FastStyleTransfer*  |       style-pointilism-9.mnn        |          [onnx-models](https://github.com/onnx/models)          | 6.4Mb |
|  *lite::mnn::cv::style::FastStyleTransfer*  |      style-rain-princess-9.mnn      |          [onnx-models](https://github.com/onnx/models)          | 6.4Mb |
|  *lite::mnn::cv::style::FastStyleTransfer*  |      style-rain-princess-8.mnn      |          [onnx-models](https://github.com/onnx/models)          | 6.4Mb |
|  *lite::mnn::cv::style::FastStyleTransfer*  |          style-candy-8.mnn          |          [onnx-models](https://github.com/onnx/models)          | 6.4Mb |
|  *lite::mnn::cv::style::FastStyleTransfer*  |         style-mosaic-9.mnn          |          [onnx-models](https://github.com/onnx/models)          | 6.4Mb |
| *lite::mnn::cv::style::FemalePhoto2Cartoon* | minivision_female_photo2cartoon.mnn | [photo2cartoon](https://github.com/minivision-ai/photo2cartoon) | 15Mb  |


## Colorization.

<div id="lite.ai.toolkit.hub.mnn-colorization"></div>

|                  Class                   |   Pretrained MNN Files   |              Rename or Converted From (Repo)              | Size  |
|:----------------------------------------:|:------------------------:|:---------------------------------------------------------:|:-----:|
| *lite::mnn::cv::colorization::Colorizer* |   eccv16-colorizer.mnn   | [colorization](https://github.com/richzhang/colorization) | 123Mb |
| *lite::mnn::cv::colorization::Colorizer* | siggraph17-colorizer.mnn | [colorization](https://github.com/richzhang/colorization) | 129Mb |


## Super Resolution.

<div id="lite.ai.toolkit.hub.mnn-super-resolution"></div>

|                  Class                   | Pretrained MNN Files |              Rename or Converted From (Repo)              | Size  |
|:----------------------------------------:|:--------------------:|:---------------------------------------------------------:|:-----:|
| *lite::mnn::cv::resolution::SubPixelCNN* |   subpixel-cnn.mnn   | [...PIXEL...](https://github.com/niazwazir/SUB_PIXEL_CNN) | 234Kb |

